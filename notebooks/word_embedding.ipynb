{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064be72f",
   "metadata": {},
   "source": [
    "# Word Embedding Model\n",
    "\n",
    "The architecture used for sentiment analysis is \"Word Embeddings\" whose guide can be viewed at the following link:\n",
    ">https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867415a",
   "metadata": {},
   "source": [
    "## Creating Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f5a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet():\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "\n",
    "class Utils():\n",
    "    def __init__(self, tweets):\n",
    "        self.tweets = tweets\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.tweets]\n",
    "    \n",
    "    def get_label(self):\n",
    "        return [x.label for x in self.tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea89e896",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f62fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 12:31:19.248605: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-18 12:31:19.248635: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48376c8c",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "\n",
    "### Read data from json.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a8e1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   awww thats a bummer  you shoulda got david carr of third day to do it d\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "file_name = '../data/Data_processed.json'\n",
    "\n",
    "tweets = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        tweets.append(Tweet(tweet['Text'], tweet['Target']))\n",
    "    \n",
    "# Taking a look at an example of our data\n",
    "print(tweets[0].text)\n",
    "print(tweets[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25305a84",
   "metadata": {},
   "source": [
    "## Creating our Tensorflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ad8d6",
   "metadata": {},
   "source": [
    "### Setting Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd2920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "SEED = 123\n",
    "DENSE_NODES = 16\n",
    "OPTIMIZER = 'adam'\n",
    "METRICS = ['accuracy']\n",
    "EPOCHS = 5\n",
    "VOCAB_SIZE = 10000\n",
    "SEQUENCE_LEN = 50\n",
    "EMBEDDING_DIM = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1294e",
   "metadata": {},
   "source": [
    "### Creating text/label datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701bd590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 12:31:34.557792: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-18 12:31:34.557846: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-18 12:31:34.557876: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mik-HP-EliteBook-840-G2): /proc/driver/nvidia/version does not exist\n",
      "2022-02-18 12:31:34.558275: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-18 12:31:35.043243: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 38400000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "dataset_text = Utils(tweets).get_text()\n",
    "dataset_labels = Utils(tweets).get_label()\n",
    "\n",
    "ds_labels = tf.convert_to_tensor(dataset_labels)\n",
    "ds_text = tf.convert_to_tensor(dataset_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c57ed",
   "metadata": {},
   "source": [
    "#### For creating our TextVectorizer Vocab(Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ba8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_text = tf.data.Dataset.from_tensors(ds_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b41311",
   "metadata": {},
   "source": [
    "## Text Vectorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d44563",
   "metadata": {},
   "source": [
    "Use the text vectorization layer to normalize, split, and map strings to integers. Note that the layer uses the custom standardization defined above.Set maximum_sequence length as all samples are not of the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed05906",
   "metadata": {},
   "source": [
    "Calling adapt mathod to build vocabulary from training dataset while also transforming our test dataset for future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657f3335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 12:31:36.049335: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 38400000 exceeds 10% of free system memory.\n",
      "2022-02-18 12:31:36.125553: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 38400000 exceeds 10% of free system memory.\n",
      "2022-02-18 12:31:36.889281: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 38400000 exceeds 10% of free system memory.\n",
      "2022-02-18 12:31:39.949213: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 316989920 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer = TextVectorization(standardize='lower_and_strip_punctuation',\n",
    "                                   max_tokens=VOCAB_SIZE,\n",
    "                                   split='whitespace',\n",
    "                                   output_mode='int',\n",
    "                                   output_sequence_length=SEQUENCE_LEN)\n",
    "\n",
    "vectorize_layer.adapt(p_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363f600",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0e377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    vectorize_layer,\n",
    "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, name='embedding'),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(DENSE_NODES, activation='relu'),\n",
    "    Dense(1, activation='sigmoid') # We want either 0 or 1 for our sentiment analysis\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b5e13",
   "metadata": {},
   "source": [
    "## Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497e2a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 30s 19ms/step - loss: 0.5096 - accuracy: 0.7559 - val_loss: 0.5622 - val_accuracy: 0.7527\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 0.4435 - accuracy: 0.8003 - val_loss: 0.4907 - val_accuracy: 0.7695\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.4304 - accuracy: 0.8030 - val_loss: 0.5631 - val_accuracy: 0.7096\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 0.4249 - accuracy: 0.8041 - val_loss: 0.5193 - val_accuracy: 0.7330\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 0.4212 - accuracy: 0.8053 - val_loss: 0.5140 - val_accuracy: 0.7376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f677c4b0340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs') # Saving statistics for tensorboard\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "             metrics=METRICS)\n",
    "\n",
    "model.fit(x=ds_text,\n",
    "         y=ds_labels,\n",
    "         batch_size=BATCH_SIZE,\n",
    "         epochs=EPOCHS, \n",
    "         validation_split=0.1,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def2dee5",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e68f1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(x):\n",
    "    if x >= 0.5:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07923019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment for this tweet is: Positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment for this tweet is:\", get_sentiment(model.predict([\"Got praised, Yay\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16089323",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b21bf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 12:34:26.565040: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tf_word_em/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/tf_word_em')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f17ba9",
   "metadata": {},
   "source": [
    "## Visualize model on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ceef539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sa_env",
   "language": "python",
   "name": "sa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
